# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/Library Notebooks/01_Datasets.ipynb.

# %% auto 0
__all__ = ['load_dataset', 'explore_dataset']

# %% ../nbs/Library Notebooks/01_Datasets.ipynb 4
import pandas as pd
import os

# %% ../nbs/Library Notebooks/01_Datasets.ipynb 6
def load_dataset(filepath : str, # full path/relative path of the dataset file
                 mode: str # read,write or append
                ) :  # -> pd.DataFrame(): # return DataFrame of dataset 
    # check if file exists
    try :
        if os.path.exists(filepath):
            print("File exists")
            
        else:
            raise File_NotFound_Exception(f"Cannot open file{filepath}")
            
    except Exception as e:
        print(e)
        return None
    
    # check if file extension is supported
    name,extension = filepath.split(".")

    try : 
        if extension == 'csv' or extension == 'xlsx' or extension == 'json':
            print(f".{extension} file extension is supported")
            data_frame = pd.read_csv(filepath)
            
        else:
            raise Unsupported_FileFormat_Exception(f"Cannot open file with extension{extension}")
            
    except Exception as e:
        print(e)
        return None
    
    else:
        return data_frame  


# %% ../nbs/Library Notebooks/01_Datasets.ipynb 7
def explore_dataset(dataset_df : pd.DataFrame,# DataFrame handler of the dataset
                    NAN_action : str , # action to take on null values
                    duplicate_action : str, # action to take on duplicate values
                    NAN_subset : list = None, # drop rows with null values in columns of NAN_subset
                    duplicate_subset : list = None, # drop rows with duplicate values in columns of dupliate_subset
                    inplace : bool = True # whether ot not to make changes in original dataset
                    ):
    try:
        
        print(f"In Dataset \nObservations : {(dataset_df.shape)[0]} \nColumns :{(dataset_df.shape)[1]}\n")

        ### null values ###
        null_values = dataset_df.isnull().sum(axis = 0)
        print(f"-----NAN values-----\n{null_values}\n")
        
        # if null values found in dataset perform NAN_action specified 
        if (null_values.sum()):
            if NAN_action =='drop': 
                dataset.dropna(inplace=inplace)
                print(f"{NAN_action} NAN successful \n")
                
                

        ### duplicates ###
        
        # we need record of each machine only once per day
        duplicate_values = dataset_df.duplicated(subset=duplicate_subset).sum()
        print(f"-----Duplicate records-----\n{duplicate_values}\n")
        
        # if null values found in dataset perform NAN_action specified 
        if duplicate_values:
            if duplicate_action =='drop': 
                dataset_df.drop_duplicates(subset= duplicate_subset, inplace=inplace)
                print(f"{NAN_action} Duplicates successful \n")
                
    
    except Exception as e:
        print(e)
        return None
    
